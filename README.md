# single_crawler
First Step To Build Big Crawler.

实验目标
---------

+ 爬取x-cold的博客：http://blog.lxstart.net/ 的全站文章（约20-30篇）

+ 结构化爬取的文章，持久化到本地（数据库、文件均可，暂时不考虑存储优化）

+ 实现一个简单的HTTP服务器对抓取的结果进行展示（文章列表+文章详情）

环境要求
---------

Nodejs: v4.3.0

代码提交须知
---------

1. 仓库地址：https://github.com/scauhci/single_crawler.git

2. 分支命名（每人一个分支）：feature/x-cold (其中x-cold为用户名)

3. 提交commit规范：https://github.com/scauhci/single_crawler/blob/master/contribute.md

4. 编码规范

    + es5 standard: https://github.com/airbnb/javascript/tree/es5-deprecated/es5

    + jshint: https://github.com/airbnb/javascript/blob/master/linters/.jshintrc


其他注意事项
---------

+ 本次练习采用使用es5

+ 请使用jshint进行代码检查，通过后方可提交（可以考虑进行git-hook）
